{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a55556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import F1Score\n",
    "import ttach as tta\n",
    "import wandb\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available else \"cpu\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665c870",
   "metadata": {},
   "source": [
    "# Split data to train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8bd36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg</td>\n",
       "      <td>greco-Roman_wrestling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4d60732e-d680-4bfd-9067-70ff8137f537.jpeg</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6853478-48c1-48b2-b104-74903730c831.jpeg</td>\n",
       "      <td>sailing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id                  label\n",
       "0  46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg               swimming\n",
       "1  ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg  greco-Roman_wrestling\n",
       "2  4d60732e-d680-4bfd-9067-70ff8137f537.jpeg                running\n",
       "3  93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg               football\n",
       "4  b6853478-48c1-48b2-b104-74903730c831.jpeg                sailing"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "# split data on train and validation \n",
    "X = df[\"image_id\"].values\n",
    "y = df[\"label\"].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y, \n",
    "                                                  shuffle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95c6ef",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655c5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test = test_data[\"image_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f0a47",
   "metadata": {},
   "source": [
    "# ToDo  \n",
    "* weighted CE +\n",
    "* full training pipeline from config\n",
    "* wandb logger\n",
    "* weights saving\n",
    "* proper model freezing (like from seminar) +\n",
    "* TTA ++\n",
    "* func for subm + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sport names to digits\n",
    "sport_to_idx = dict(zip(np.unique(df[\"label\"].values), \n",
    "                        [i for i in range(len(np.unique(df[\"label\"].values)))]))\n",
    "idx_to_sport = dict(zip([i for i in range(len(np.unique(df[\"label\"].values)))],\n",
    "                        np.unique(df[\"label\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bc7acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = df[\"label\"].unique()\n",
    "class_weights = class_weight.compute_class_weight(class_weight=\"balanced\",\n",
    "                                                classes=classes,\n",
    "                                                y=df[\"label\"].values)\n",
    "class_weights = dict(zip(classes, class_weights))\n",
    "class_weights = {sport_to_idx[sport] : class_weights[sport] for sport in class_weights}\n",
    "class_weights = np.array(sorted(class_weights.items(), key=lambda x: x[0]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e0e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SportsDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 path_to_imgs, \n",
    "                 img_list, \n",
    "                 label_list,\n",
    "                 sport_dict, \n",
    "                 is_test=False,\n",
    "                 transforms=None):\n",
    "        \n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.image_list = img_list\n",
    "        self.label_list = label_list\n",
    "        self.sport_dict = sport_dict\n",
    "        self.is_test = is_test\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        image = Image.open(os.path.join(self.path_to_imgs, img_name)).convert(\"RGB\")\n",
    "        if self.is_test:\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image)\n",
    "            return image\n",
    "        label = self.label_list[idx]\n",
    "        encoded_label = self.sport_dict[label]\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, encoded_label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73811a4d",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9ba09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([T.RandomRotation(degrees=90),\n",
    "                              T.RandomVerticalFlip(),\n",
    "                              T.RandomHorizontalFlip(),\n",
    "                              T.ToTensor(),\n",
    "                              T.Resize((384, 384)),\n",
    "                              T.RandomErasing(),\n",
    "                              T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                    std=[0.229, 0.224, 0.225]),\n",
    "                             ])\n",
    "tta_tf = tta.Compose([tta.HorizontalFlip(), \n",
    "                      tta.Rotate90([0, 90, 180, 270]), \n",
    "                      tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a79914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transforms = T.Compose([T.ToTensor(), \n",
    "                        T.Resize((384, 384)),\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                    std=[0.229, 0.224, 0.225])]) # from model default cfg\n",
    "# mb add flips to train part\n",
    "val_transforms = simple_transforms\n",
    "train_dataset = SportsDataset(path_to_imgs=\"train/\",\n",
    "                              img_list=X_train,\n",
    "                              label_list=y_train,\n",
    "                              sport_dict=sport_to_idx,\n",
    "                              is_test=False,\n",
    "                              transforms=train_transforms)\n",
    "\n",
    "val_dataset = SportsDataset(path_to_imgs=\"train/\",\n",
    "                            img_list=X_val,\n",
    "                            label_list=y_val,\n",
    "                            sport_dict=sport_to_idx, \n",
    "                            is_test=False,\n",
    "                            transforms=val_transforms)\n",
    "\n",
    "test_dataset = SportsDataset(path_to_imgs=\"test/\",\n",
    "                             img_list=X_test,\n",
    "                             label_list=None,\n",
    "                             sport_dict=sport_to_idx,\n",
    "                             is_test=True,\n",
    "                             transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e4beb",
   "metadata": {},
   "source": [
    "Did it once in order to compute statistics\n",
    "\n",
    "Train mean R: 0.0, G: 0.002, B: -0.001  \n",
    "Train std R: 1.002, G: 0.999, B: 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ff6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835da436",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bff91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training(model, mode):\n",
    "    # disable traning for all layers\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "#     for p in model.stages[3].parameters():\n",
    "#         print(p.requires_grad) # double check\n",
    "    if mode == \"stage3\":\n",
    "        model.stages[3].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "    #         print(p.requires_grad) # double check\n",
    "    elif mode == \"stage3_block2\":\n",
    "        model.stages[3].blocks[2].train()\n",
    "        for p in model.stages[3].blocks[2].parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    elif mode == \"stage2\":\n",
    "        model.stages[2].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "        model.stages[2].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "    model.head.train()\n",
    "    for p in model.head.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit(model, \n",
    "                  test_loader, \n",
    "                  label_mapper,\n",
    "                  experiment_name,\n",
    "                  path_to_test_csv=\"test.csv\",\n",
    "                  device=device,\n",
    "                  tta=None):\n",
    "    res = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            if tta:\n",
    "                probs = []\n",
    "                for tf in tta:\n",
    "                    aug_data = tf.augment_image(batch)\n",
    "                    out = model(aug_data)\n",
    "                    probs.append(out)\n",
    "                out = torch.stack(probs, dim=0)\n",
    "                out = out.mean(dim=0)\n",
    "            else:\n",
    "                out = model(batch)\n",
    "            labels = torch.argmax(out, dim=1).tolist()\n",
    "            res.extend(labels)\n",
    "    \n",
    "    for idx in range(len(res)):\n",
    "        res[idx] = label_mapper[res[idx]]\n",
    "    \n",
    "    subm = pd.read_csv(path_to_test_csv)\n",
    "    subm[\"label\"] = res\n",
    "    subm.to_csv(f\"{experiment_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3e6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_train(model,\n",
    "                 epoch_num,\n",
    "                 criterion,\n",
    "                 optimizer, \n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 f1,\n",
    "                 training_mode,\n",
    "                 experiment_name,\n",
    "                 log_frequency,\n",
    "                 path_to_save_weights=\"weights/\",\n",
    "                 tta=None,\n",
    "                 scheduler=None,\n",
    "                 device=device\n",
    "                ):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    val_loss = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    best_val_score = 0\n",
    "    \n",
    "    for _ in tqdm(range(epoch_num)):\n",
    "\n",
    "        set_training(model, training_mode)\n",
    "        \n",
    "        batch_f1_train = 0\n",
    "        batch_loss_train = 0\n",
    "\n",
    "        batch_cnt = 0\n",
    "        \n",
    "        for (imgs, labels) in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "\n",
    "            f1_micro = f1(out, labels)\n",
    "            batch_f1_train += f1_micro\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            batch_loss_train += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_cnt += 1\n",
    "            if batch_cnt % log_frequency == 0:\n",
    "                wandb.log({\"train micro f1\": f1_micro})\n",
    "                wandb.log({\"train loss\": loss})\n",
    "#                 print(f\"train f1 {f1_micro}, train loss {loss.item()}, batch_numer: {batch_cnt}\")\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        train_loss.append(batch_loss_train / len(train_loader))\n",
    "        train_f1.append(batch_f1_train / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            batch_f1_val = 0\n",
    "            batch_loss_val = 0\n",
    "            batch_cnt = 0\n",
    "\n",
    "            for (imgs, labels) in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                if tta:\n",
    "                    probs = []\n",
    "                    for tf in tta:\n",
    "                        aug_data = tf.augment_image(imgs)\n",
    "                        out = model(aug_data)\n",
    "                        probs.append(out)\n",
    "                    res = torch.stack(probs, dim=0)\n",
    "                    out = res.mean(dim=0)\n",
    "                else:\n",
    "                    out = model(imgs)\n",
    "\n",
    "                f1_micro = f1(out, labels)\n",
    "                batch_f1_val += f1_micro\n",
    "\n",
    "                loss = criterion(out, labels)\n",
    "                batch_loss_val += loss.item()\n",
    "                batch_cnt += 1\n",
    "                if batch_cnt % log_frequency == 0:\n",
    "                    wandb.log({\"val micro f1\": f1_micro})\n",
    "                    wandb.log({\"val loss\": loss})\n",
    "#                     print(f\"val f1 {f1_micro}, val loss {loss.item()},  batch_numer: {batch_cnt}\")\n",
    "\n",
    "            val_loss.append(batch_loss_val / len(val_loader))\n",
    "            val_f1.append(batch_f1_val / len(val_loader))\n",
    "            # save weights\n",
    "            if val_f1[-1] >= best_val_score:\n",
    "                best_val_score = val_f1[-1]\n",
    "                torch.save(model.state_dict(), os.path.join(path_to_save_weights, f\"{experiment_name}.pth\"))\n",
    "            \n",
    "            wandb.log({\"best val micro f1\": best_val_score})\n",
    "            \n",
    "        print(f\"Train F1: {train_f1[-1]} Val F1: {val_f1[-1]}\")    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a351c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttatf = tta.Compose(\n",
    "#     [\n",
    "#         tta.HorizontalFlip(),\n",
    "#         tta.Rotate90(angles=[0, 90, 270]),\n",
    "#         tta.Multiply(factors=[0.9, 1]),        \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model = timm.create_model(\"convnext_small_384_in22ft1k\", pretrained=True, num_classes=30)\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(class_weights).to(device, dtype=torch.float32))\n",
    "# f1_score = F1Score(task=\"multiclass\", num_classes=30, average=\"micro\").to(device)\n",
    "# optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "# epoch_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add722f0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1935ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\" : \"convnext_small_384_in22ft1k\", \n",
    "    \"tta\" : tta_tf,\n",
    "    \"criterion\": \"weighted\", \n",
    "    \"experiment_name\": \"stage2_weighted_CE_wo_TTA_wo_TA_10_epoch_tta_tta_reduce_mean_final_try_third\", \n",
    "    \"training_mode\" : \"stage2\",\n",
    "    \"epoch_num\" : 30, \n",
    "    \"log_frequency\" : 10, \n",
    "    \"scheduler\" : \"step_lr\",\n",
    "    \"scheduler_step\": 5,\n",
    "    \"sheduler_gamma\": 0.1,\n",
    "    \"lr\" : 0.001, \n",
    "    \"device\" : \"cuda:2\", \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324dbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = config[\"experiment_name\"]\n",
    "device = config[\"device\"]\n",
    "log_frequency = config[\"log_frequency\"]\n",
    "epoch_num = config[\"epoch_num\"]\n",
    "training_mode = config[\"training_mode\"] \n",
    "lr = config[\"lr\"]\n",
    "\n",
    "model = timm.create_model(config[\"model\"], pretrained=True, num_classes=30) \n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "if config[\"criterion\"] == \"weighted\":\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(class_weights).to(device, dtype=torch.float32))\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "if config[\"scheduler\"] == \"step_lr\":\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optim, \n",
    "                                                step_size=config[\"scheduler_step\"],\n",
    "                                                gamma=config[\"sheduler_gamma\"])    \n",
    "else:\n",
    "    scheduler = None\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=30, average=\"micro\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e39e0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmasny\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/notebooks/cv_made/wandb/run-20230416_183632-56mb7o1v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmasny/made_cv_hw/runs/56mb7o1v' target=\"_blank\">stage2_weighted_CE_wo_TTA_wo_TA_10_epoch_tta_tta_reduce_mean_final_try_third</a></strong> to <a href='https://wandb.ai/dmasny/made_cv_hw' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmasny/made_cv_hw' target=\"_blank\">https://wandb.ai/dmasny/made_cv_hw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmasny/made_cv_hw/runs/56mb7o1v' target=\"_blank\">https://wandb.ai/dmasny/made_cv_hw/runs/56mb7o1v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▎                                                                                                                                                           | 1/30 [1:14:04<35:48:07, 4444.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8401857018470764 Val F1: 0.9220648407936096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████▋                                                                                                                                                      | 2/30 [2:28:11<34:34:50, 4446.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8974441885948181 Val F1: 0.9318040609359741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████                                                                                                                                                 | 3/30 [3:42:19<33:21:01, 4446.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9151175022125244 Val F1: 0.9304555654525757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████████████▍                                                                                                                                           | 4/30 [4:56:25<32:06:54, 4446.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9264659285545349 Val F1: 0.9380480051040649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████████████████▊                                                                                                                                      | 5/30 [6:10:30<30:52:26, 4445.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9364791512489319 Val F1: 0.937085747718811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████████▏                                                                                                                                | 6/30 [7:24:33<29:37:59, 4445.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9587464332580566 Val F1: 0.9462186694145203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████████████████████████▌                                                                                                                           | 7/30 [8:38:37<28:23:47, 4444.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9654787182807922 Val F1: 0.9456684589385986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████████████████████████▉                                                                                                                      | 8/30 [9:52:40<27:09:28, 4444.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9674570560455322 Val F1: 0.9466587901115417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████████████████████████████                                                                                                                | 9/30 [11:06:44<25:55:27, 4444.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.972438395023346 Val F1: 0.9458885788917542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████████████████████████████████                                                                                                          | 10/30 [12:20:49<24:41:25, 4444.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9719558358192444 Val F1: 0.9454483985900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████████████████████████████████▎                                                                                                    | 11/30 [13:34:57<23:27:42, 4445.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9742963314056396 Val F1: 0.9467688202857971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████████████████████████████████████▉                                                                                          | 13/30 [16:03:08<20:59:30, 4445.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9762672781944275 Val F1: 0.9474290609359741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████████████████████████████████████████▏                                                                                    | 14/30 [17:17:15<19:45:33, 4445.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9775052070617676 Val F1: 0.9469888806343079\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"made_cv_hw\", \n",
    "           entity=\"dmasny\",\n",
    "           name=experiment_name, \n",
    "           config=config)\n",
    "\n",
    "simple_train(model=model, \n",
    "             epoch_num=epoch_num, \n",
    "             criterion=criterion,\n",
    "             optimizer=optim,\n",
    "             train_loader=train_loader,\n",
    "             val_loader=val_loader,\n",
    "             f1=f1_score,\n",
    "             training_mode=training_mode,\n",
    "             experiment_name=experiment_name,\n",
    "             log_frequency=log_frequency,\n",
    "             path_to_save_weights=\"weights/\",\n",
    "             tta=tta_tf,\n",
    "             scheduler=scheduler,\n",
    "             device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbfd85",
   "metadata": {},
   "source": [
    "# План экспериментов\n",
    "* stage3 block2 / stage3\n",
    "* with tta /without tta\n",
    "* epoch 10-50\n",
    "* weighted CE / standard CE\n",
    "* train augm / wo augm\n",
    "* another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725855b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {learning_rate': lr,\n",
    "#                 'weight_decay': wd,\n",
    "#                 'epochs': epoches,\n",
    "#                 'training_batch_size' : batch_size,\n",
    "#                 'validation_batch_size' : batch_size,\n",
    "#                 'loops_config': 'allow loops',\n",
    "#                 'weight_config': 'weighted',\n",
    "#                 'split_number': split,\n",
    "#                 'criterion': criterion,    \n",
    "#                 'node_representation_size': train_dataset.num_node_features, \n",
    "#                 'activation' : 'without relu at the end',\n",
    "#                 'model': {\n",
    "#                                 'num_graph_conv_blocks': 2,\n",
    "#                                 'hidden_channels' : hidden_channels,\n",
    "#                                 'activation' : 'ReLU',\n",
    "#                                 'readout': 'global_mean_pool'}}\n",
    "\n",
    "#         wandb.init(project = 'resting_state_eeg', \n",
    "#                 entity = 'dmasny',\n",
    "#                 name = experiment_name, \n",
    "#                 config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "927ec53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): Sequential(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = timm.create_model(\"convnext_small_384_in22ft1k\", pretrained=True, num_classes=30)\n",
    "m.load_state_dict(torch.load(\"weights/stage3_weighted_CE_wo_TTA_wo_TA_10_epoch.pth\"))\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3609caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152/152 [13:14<00:00,  5.22s/it]\n"
     ]
    }
   ],
   "source": [
    "create_submit(m,\n",
    "              test_loader,\n",
    "              idx_to_sport,\n",
    "              experiment_name=\"stage3_weighted_CE_wo_TTA_wo_TA_10_epoch\",\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b306d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a55556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import F1Score\n",
    "import ttach as tta\n",
    "import wandb\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available else \"cpu\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665c870",
   "metadata": {},
   "source": [
    "# Split data to train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8bd36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg</td>\n",
       "      <td>greco-Roman_wrestling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4d60732e-d680-4bfd-9067-70ff8137f537.jpeg</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6853478-48c1-48b2-b104-74903730c831.jpeg</td>\n",
       "      <td>sailing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id                  label\n",
       "0  46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg               swimming\n",
       "1  ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg  greco-Roman_wrestling\n",
       "2  4d60732e-d680-4bfd-9067-70ff8137f537.jpeg                running\n",
       "3  93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg               football\n",
       "4  b6853478-48c1-48b2-b104-74903730c831.jpeg                sailing"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "# split data on train and validation \n",
    "X = df[\"image_id\"].values\n",
    "y = df[\"label\"].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y, \n",
    "                                                  shuffle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95c6ef",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655c5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test = test_data[\"image_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f0a47",
   "metadata": {},
   "source": [
    "# ToDo  \n",
    "* weighted CE +\n",
    "* full training pipeline from config\n",
    "* wandb logger\n",
    "* weights saving\n",
    "* proper model freezing (like from seminar) +\n",
    "* TTA ++\n",
    "* func for subm + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sport names to digits\n",
    "sport_to_idx = dict(zip(np.unique(df[\"label\"].values), \n",
    "                        [i for i in range(len(np.unique(df[\"label\"].values)))]))\n",
    "idx_to_sport = dict(zip([i for i in range(len(np.unique(df[\"label\"].values)))],\n",
    "                        np.unique(df[\"label\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bc7acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = df[\"label\"].unique()\n",
    "class_weights = class_weight.compute_class_weight(class_weight=\"balanced\",\n",
    "                                                classes=classes,\n",
    "                                                y=df[\"label\"].values)\n",
    "class_weights = dict(zip(classes, class_weights))\n",
    "class_weights = {sport_to_idx[sport] : class_weights[sport] for sport in class_weights}\n",
    "class_weights = np.array(sorted(class_weights.items(), key=lambda x: x[0]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e0e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SportsDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 path_to_imgs, \n",
    "                 img_list, \n",
    "                 label_list,\n",
    "                 sport_dict, \n",
    "                 is_test=False,\n",
    "                 transforms=None):\n",
    "        \n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.image_list = img_list\n",
    "        self.label_list = label_list\n",
    "        self.sport_dict = sport_dict\n",
    "        self.is_test = is_test\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        image = Image.open(os.path.join(self.path_to_imgs, img_name)).convert(\"RGB\")\n",
    "        if self.is_test:\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image)\n",
    "            return image\n",
    "        label = self.label_list[idx]\n",
    "        encoded_label = self.sport_dict[label]\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, encoded_label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73811a4d",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9ba09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([T.RandomRotation(degrees=90),\n",
    "                              T.RandomVerticalFlip(),\n",
    "                              T.RandomHorizontalFlip(),\n",
    "                              T.ToTensor(),\n",
    "                              T.Resize((224, 224)),\n",
    "                              T.RandomErasing(),\n",
    "                              T.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "                                    std=[0.5, 0.5, 0.5])])\n",
    "tta_tf = tta.Compose([tta.HorizontalFlip(), \n",
    "                      tta.Rotate90([0, 90, 180, 270]), \n",
    "#                       tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a79914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transforms = T.Compose([T.ToTensor(), \n",
    "                        T.Resize((224, 224)),\n",
    "                        T.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "                                    std=[0.5, 0.5, 0.5])]) # from model default cfg\n",
    "# mb add flips to train part\n",
    "val_transforms = simple_transforms\n",
    "train_dataset = SportsDataset(path_to_imgs=\"train/\",\n",
    "                              img_list=X_train,\n",
    "                              label_list=y_train,\n",
    "                              sport_dict=sport_to_idx,\n",
    "                              is_test=False,\n",
    "                              transforms=train_transforms)\n",
    "\n",
    "val_dataset = SportsDataset(path_to_imgs=\"train/\",\n",
    "                            img_list=X_val,\n",
    "                            label_list=y_val,\n",
    "                            sport_dict=sport_to_idx, \n",
    "                            is_test=False,\n",
    "                            transforms=val_transforms)\n",
    "\n",
    "test_dataset = SportsDataset(path_to_imgs=\"test/\",\n",
    "                             img_list=X_test,\n",
    "                             label_list=None,\n",
    "                             sport_dict=sport_to_idx,\n",
    "                             is_test=True,\n",
    "                             transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e4beb",
   "metadata": {},
   "source": [
    "Did it once in order to compute statistics\n",
    "\n",
    "Train mean R: 0.0, G: 0.002, B: -0.001  \n",
    "Train std R: 1.002, G: 0.999, B: 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ff6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835da436",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bff91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training(model, mode):\n",
    "    # disable traning for all layers\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "#     for p in model.stages[3].parameters():\n",
    "#         print(p.requires_grad) # double check\n",
    "    if mode == \"stage3\":\n",
    "        model.stages[3].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "    #         print(p.requires_grad) # double check\n",
    "    elif mode == \"stage3_block2\":\n",
    "        model.stages[3].blocks[2].train()\n",
    "        for p in model.stages[3].blocks[2].parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    elif mode == \"stage2\":\n",
    "        model.stages[2].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "        model.stages[2].train()\n",
    "        for p in model.stages[3].parameters():\n",
    "            p.requires_grad = True\n",
    "    elif mode == \"vit_block31\":\n",
    "        model.blocks[31].train()\n",
    "        for p in model.blocks[31].parameters():\n",
    "            p.requires_grad = True\n",
    "    elif mode == \"beit_block23\":\n",
    "        model.blocks[23].train()\n",
    "        for p in model.blocks[23].parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "    model.head.train()\n",
    "    for p in model.head.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit(model, \n",
    "                  test_loader, \n",
    "                  label_mapper,\n",
    "                  experiment_name,\n",
    "                  path_to_test_csv=\"test.csv\",\n",
    "                  device=device,\n",
    "                  tta=None):\n",
    "    res = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            if tta:\n",
    "                probs = []\n",
    "                for tf in tta:\n",
    "                    aug_data = tf.augment_image(batch)\n",
    "                    out = model(aug_data)\n",
    "                    probs.append(out)\n",
    "                out = torch.stack(probs, dim=0)\n",
    "                out = out.mean(dim=0)\n",
    "            else:\n",
    "                out = model(batch)\n",
    "            labels = torch.argmax(out, dim=1).tolist()\n",
    "            res.extend(labels)\n",
    "    \n",
    "    for idx in range(len(res)):\n",
    "        res[idx] = label_mapper[res[idx]]\n",
    "    \n",
    "    subm = pd.read_csv(path_to_test_csv)\n",
    "    subm[\"label\"] = res\n",
    "    subm.to_csv(f\"{experiment_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3e6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_train(model,\n",
    "                 epoch_num,\n",
    "                 criterion,\n",
    "                 optimizer, \n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 f1,\n",
    "                 training_mode,\n",
    "                 experiment_name,\n",
    "                 log_frequency,\n",
    "                 path_to_save_weights=\"weights/\",\n",
    "                 tta=None,\n",
    "                 scheduler=None,\n",
    "                 device=device\n",
    "                ):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    val_loss = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    best_val_score = 0\n",
    "    \n",
    "    for _ in tqdm(range(epoch_num)):\n",
    "\n",
    "        set_training(model, training_mode)\n",
    "        \n",
    "        batch_f1_train = 0\n",
    "        batch_loss_train = 0\n",
    "\n",
    "        batch_cnt = 0\n",
    "        \n",
    "        for (imgs, labels) in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "\n",
    "            f1_micro = f1(out, labels)\n",
    "            batch_f1_train += f1_micro\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            batch_loss_train += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_cnt += 1\n",
    "            if batch_cnt % log_frequency == 0:\n",
    "                wandb.log({\"train micro f1\": f1_micro})\n",
    "                wandb.log({\"train loss\": loss})\n",
    "#                 print(f\"train f1 {f1_micro}, train loss {loss.item()}, batch_numer: {batch_cnt}\")\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        train_loss.append(batch_loss_train / len(train_loader))\n",
    "        train_f1.append(batch_f1_train / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            batch_f1_val = 0\n",
    "            batch_loss_val = 0\n",
    "            batch_cnt = 0\n",
    "\n",
    "            for (imgs, labels) in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                if tta:\n",
    "                    probs = []\n",
    "                    for tf in tta:\n",
    "                        aug_data = tf.augment_image(imgs)\n",
    "                        out = model(aug_data)\n",
    "                        probs.append(out)\n",
    "                    res = torch.stack(probs, dim=0)\n",
    "                    out = res.mean(dim=0)\n",
    "                else:\n",
    "                    out = model(imgs)\n",
    "\n",
    "                f1_micro = f1(out, labels)\n",
    "                batch_f1_val += f1_micro\n",
    "\n",
    "                loss = criterion(out, labels)\n",
    "                batch_loss_val += loss.item()\n",
    "                batch_cnt += 1\n",
    "                if batch_cnt % log_frequency == 0:\n",
    "                    wandb.log({\"val micro f1\": f1_micro})\n",
    "                    wandb.log({\"val loss\": loss})\n",
    "#                     print(f\"val f1 {f1_micro}, val loss {loss.item()},  batch_numer: {batch_cnt}\")\n",
    "\n",
    "            val_loss.append(batch_loss_val / len(val_loader))\n",
    "            val_f1.append(batch_f1_val / len(val_loader))\n",
    "            # save weights\n",
    "            if val_f1[-1] >= best_val_score:\n",
    "                best_val_score = val_f1[-1]\n",
    "                torch.save(model.state_dict(), os.path.join(path_to_save_weights, f\"{experiment_name}.pth\"))\n",
    "            \n",
    "            wandb.log({\"best val micro f1\": best_val_score})\n",
    "            \n",
    "        print(f\"Train F1: {train_f1[-1]} Val F1: {val_f1[-1]}\")    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a351c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttatf = tta.Compose(\n",
    "#     [\n",
    "#         tta.HorizontalFlip(),\n",
    "#         tta.Rotate90(angles=[0, 90, 270]),\n",
    "#         tta.Multiply(factors=[0.9, 1]),        \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model = timm.create_model(\"convnext_small_384_in22ft1k\", pretrained=True, num_classes=30)\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(class_weights).to(device, dtype=torch.float32))\n",
    "# f1_score = F1Score(task=\"multiclass\", num_classes=30, average=\"micro\").to(device)\n",
    "# optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "# epoch_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add722f0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1935ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\" : \"beit_large_patch16_224_in22k\", \n",
    "    \"tta\" : None,\n",
    "    \"criterion\": \"weighted\", \n",
    "    \"experiment_name\": \"beit_large_patch16_224_in22k_train_aug\", \n",
    "    \"training_mode\" : \"beit_block23\",\n",
    "    \"epoch_num\" : 30, \n",
    "    \"log_frequency\" : 10, \n",
    "    \"scheduler\" : \"step_lr\",\n",
    "    \"scheduler_step\": 4,\n",
    "    \"sheduler_gamma\": 0.1,\n",
    "    \"lr\" : 0.001, \n",
    "    \"device\" : \"cuda:2\", \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324dbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = config[\"experiment_name\"]\n",
    "device = config[\"device\"]\n",
    "log_frequency = config[\"log_frequency\"]\n",
    "epoch_num = config[\"epoch_num\"]\n",
    "training_mode = config[\"training_mode\"] \n",
    "lr = config[\"lr\"]\n",
    "\n",
    "model = timm.create_model(config[\"model\"], pretrained=True, num_classes=30) \n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "if config[\"criterion\"] == \"weighted\":\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(class_weights).to(device, dtype=torch.float32))\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "if config[\"scheduler\"] == \"step_lr\":\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optim, \n",
    "                                                step_size=config[\"scheduler_step\"],\n",
    "                                                gamma=config[\"sheduler_gamma\"])    \n",
    "else:\n",
    "    scheduler = None\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=30, average=\"micro\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e39e0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmasny\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/notebooks/cv_made/wandb/run-20230417_195901-7emafedv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmasny/made_cv_hw/runs/7emafedv' target=\"_blank\">beit_large_patch16_224_in22k_train_aug</a></strong> to <a href='https://wandb.ai/dmasny/made_cv_hw' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmasny/made_cv_hw' target=\"_blank\">https://wandb.ai/dmasny/made_cv_hw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmasny/made_cv_hw/runs/7emafedv' target=\"_blank\">https://wandb.ai/dmasny/made_cv_hw/runs/7emafedv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/30 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmade_cv_hw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m            entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdmasny\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m            name\u001b[38;5;241m=\u001b[39mexperiment_name, \n\u001b[1;32m      4\u001b[0m            config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m----> 6\u001b[0m \u001b[43msimple_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m             \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43mf1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf1_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtraining_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlog_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m             \u001b[49m\u001b[43mpath_to_save_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m             \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36msimple_train\u001b[0;34m(model, epoch_num, criterion, optimizer, train_loader, val_loader, f1, training_mode, experiment_name, log_frequency, path_to_save_weights, tta, scheduler, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m imgs, labels \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m out \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m---> 38\u001b[0m f1_micro \u001b[38;5;241m=\u001b[39m \u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m batch_f1_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f1_micro\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, labels)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchmetrics/metric.py:236\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchmetrics/metric.py:302\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchmetrics/metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchmetrics/classification/stat_scores.py:315\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 315\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    319\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    320\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    321\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/stat_scores.py:303\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and `preds` should be (N, C, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n\u001b[0;32m--> 303\u001b[0m num_unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     check \u001b[38;5;241m=\u001b[39m num_unique_values \u001b[38;5;241m>\u001b[39m num_classes\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/functional.py:885\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 885\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/functional.py:799\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    791\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    793\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"made_cv_hw\", \n",
    "           entity=\"dmasny\",\n",
    "           name=experiment_name, \n",
    "           config=config)\n",
    "\n",
    "simple_train(model=model, \n",
    "             epoch_num=epoch_num, \n",
    "             criterion=criterion,\n",
    "             optimizer=optim,\n",
    "             train_loader=train_loader,\n",
    "             val_loader=val_loader,\n",
    "             f1=f1_score,\n",
    "             training_mode=training_mode,\n",
    "             experiment_name=experiment_name,\n",
    "             log_frequency=log_frequency,\n",
    "             path_to_save_weights=\"weights/\",\n",
    "             tta=None,\n",
    "             scheduler=scheduler,\n",
    "             device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbfd85",
   "metadata": {},
   "source": [
    "# План экспериментов\n",
    "* stage3 block2 / stage3\n",
    "* with tta /without tta\n",
    "* epoch 10-50\n",
    "* weighted CE / standard CE\n",
    "* train augm / wo augm\n",
    "* another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725855b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {learning_rate': lr,\n",
    "#                 'weight_decay': wd,\n",
    "#                 'epochs': epoches,\n",
    "#                 'training_batch_size' : batch_size,\n",
    "#                 'validation_batch_size' : batch_size,\n",
    "#                 'loops_config': 'allow loops',\n",
    "#                 'weight_config': 'weighted',\n",
    "#                 'split_number': split,\n",
    "#                 'criterion': criterion,    \n",
    "#                 'node_representation_size': train_dataset.num_node_features, \n",
    "#                 'activation' : 'without relu at the end',\n",
    "#                 'model': {\n",
    "#                                 'num_graph_conv_blocks': 2,\n",
    "#                                 'hidden_channels' : hidden_channels,\n",
    "#                                 'activation' : 'ReLU',\n",
    "#                                 'readout': 'global_mean_pool'}}\n",
    "\n",
    "#         wandb.init(project = 'resting_state_eeg', \n",
    "#                 entity = 'dmasny',\n",
    "#                 name = experiment_name, \n",
    "#                 config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927ec53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beit(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=1024, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = timm.create_model(\"beit_large_patch16_224_in22k\", pretrained=True, num_classes=30)\n",
    "m.load_state_dict(torch.load(\"weights/beit_large_patch16_224_in22k_train_aug.pth\"))\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▋                                                                                                                                                            | 2/38 [04:27<1:20:20, 133.90s/it]"
     ]
    }
   ],
   "source": [
    "create_submit(m,\n",
    "              test_loader,\n",
    "              idx_to_sport,\n",
    "              experiment_name=\"beit_aug_tta\",\n",
    "              tta=tta_tf,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b306d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
